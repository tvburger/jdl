<!DOCTYPE HTML>
<html lang>
<head>
<!-- Generated by javadoc (24) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: net.tvburger.jdl.mlp, class: MLPXorMain">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../resource-files/stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">package net.tvburger.jdl.mlp;</span>
<span class="source-line-no">002</span><span id="line-2"></span>
<span class="source-line-no">003</span><span id="line-3">import net.tvburger.jdl.common.numbers.JavaNumberTypeSupport;</span>
<span class="source-line-no">004</span><span id="line-4">import net.tvburger.jdl.datasets.LogicalDataSets;</span>
<span class="source-line-no">005</span><span id="line-5">import net.tvburger.jdl.model.DataSet;</span>
<span class="source-line-no">006</span><span id="line-6">import net.tvburger.jdl.model.nn.NeuralNetwork;</span>
<span class="source-line-no">007</span><span id="line-7">import net.tvburger.jdl.model.nn.NeuralNetworks;</span>
<span class="source-line-no">008</span><span id="line-8">import net.tvburger.jdl.model.nn.training.initializers.NeuralNetworkInitializer;</span>
<span class="source-line-no">009</span><span id="line-9">import net.tvburger.jdl.model.nn.training.initializers.XavierInitializer;</span>
<span class="source-line-no">010</span><span id="line-10">import net.tvburger.jdl.model.nn.training.optimizers.BackPropagation;</span>
<span class="source-line-no">011</span><span id="line-11">import net.tvburger.jdl.model.nn.training.optimizers.NeuralNetworkOptimizers;</span>
<span class="source-line-no">012</span><span id="line-12">import net.tvburger.jdl.model.scalars.activations.Activations;</span>
<span class="source-line-no">013</span><span id="line-13">import net.tvburger.jdl.model.training.ObjectiveFunction;</span>
<span class="source-line-no">014</span><span id="line-14">import net.tvburger.jdl.model.training.Trainer;</span>
<span class="source-line-no">015</span><span id="line-15">import net.tvburger.jdl.model.training.loss.Objectives;</span>
<span class="source-line-no">016</span><span id="line-16">import net.tvburger.jdl.model.training.optimizer.GradientDescentOptimizer;</span>
<span class="source-line-no">017</span><span id="line-17">import net.tvburger.jdl.model.training.optimizer.steps.AdamW;</span>
<span class="source-line-no">018</span><span id="line-18">import net.tvburger.jdl.model.training.regimes.ChainedRegime;</span>
<span class="source-line-no">019</span><span id="line-19">import net.tvburger.jdl.model.training.regimes.Regimes;</span>
<span class="source-line-no">020</span><span id="line-20"></span>
<span class="source-line-no">021</span><span id="line-21">import java.util.Arrays;</span>
<span class="source-line-no">022</span><span id="line-22"></span>
<span class="source-line-no">023</span><span id="line-23">public class MLPXorMain {</span>
<span class="source-line-no">024</span><span id="line-24"></span>
<span class="source-line-no">025</span><span id="line-25">    public static void main(String[] args) {</span>
<span class="source-line-no">026</span><span id="line-26">        DataSet&lt;Float&gt; dataSet = LogicalDataSets.xor().load();</span>
<span class="source-line-no">027</span><span id="line-27">        DataSet&lt;Float&gt; trainingSet = dataSet;</span>
<span class="source-line-no">028</span><span id="line-28">        DataSet&lt;Float&gt; testSet = dataSet;</span>
<span class="source-line-no">029</span><span id="line-29"></span>
<span class="source-line-no">030</span><span id="line-30">        MultiLayerPerceptron mlp = MultiLayerPerceptron.create(Activations.sigmoid(), Activations.sigmoid(), 2, 2, 1);</span>
<span class="source-line-no">031</span><span id="line-31"></span>
<span class="source-line-no">032</span><span id="line-32">        NeuralNetworkInitializer initializer = new XavierInitializer();</span>
<span class="source-line-no">033</span><span id="line-33">        ObjectiveFunction&lt;Float&gt; objective = Objectives.bCE(JavaNumberTypeSupport.FLOAT);</span>
<span class="source-line-no">034</span><span id="line-34">        GradientDescentOptimizer&lt;NeuralNetwork, Float&gt; optimizer = NeuralNetworkOptimizers.adamW();</span>
<span class="source-line-no">035</span><span id="line-35">        ChainedRegime regime = Regimes.dumpNodes().epochs(1_000).reportObjective().batch();</span>
<span class="source-line-no">036</span><span id="line-36">        Trainer&lt;MultiLayerPerceptron, Float&gt; mlpTrainer = Trainer.of(initializer, objective, optimizer, regime);</span>
<span class="source-line-no">037</span><span id="line-37">        mlpTrainer.train(mlp, trainingSet);</span>
<span class="source-line-no">038</span><span id="line-38"></span>
<span class="source-line-no">039</span><span id="line-39">        NeuralNetworks.dump(mlp);</span>
<span class="source-line-no">040</span><span id="line-40"></span>
<span class="source-line-no">041</span><span id="line-41">        for (DataSet.Sample&lt;Float&gt; sample : testSet) {</span>
<span class="source-line-no">042</span><span id="line-42">            Float[] estimate = mlp.estimate(sample.features());</span>
<span class="source-line-no">043</span><span id="line-43">            System.out.println("real = " + Arrays.toString(sample.targetOutputs()) + " vs estimated = " + Arrays.toString(estimate) + " | features " + Arrays.toString(sample.features()));</span>
<span class="source-line-no">044</span><span id="line-44">        }</span>
<span class="source-line-no">045</span><span id="line-45">    }</span>
<span class="source-line-no">046</span><span id="line-46">}</span>




























































</pre>
</div>
</main>
</body>
</html>
