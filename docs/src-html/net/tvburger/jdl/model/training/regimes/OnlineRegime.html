<!DOCTYPE HTML>
<html lang>
<head>
<!-- Generated by javadoc (24) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: net.tvburger.jdl.model.training.regimes, class: OnlineRegime">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../../resource-files/stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">package net.tvburger.jdl.model.training.regimes;</span>
<span class="source-line-no">002</span><span id="line-2"></span>
<span class="source-line-no">003</span><span id="line-3">import net.tvburger.jdl.common.patterns.Strategy;</span>
<span class="source-line-no">004</span><span id="line-4">import net.tvburger.jdl.model.DataSet;</span>
<span class="source-line-no">005</span><span id="line-5">import net.tvburger.jdl.model.EstimationFunction;</span>
<span class="source-line-no">006</span><span id="line-6">import net.tvburger.jdl.model.training.ObjectiveFunction;</span>
<span class="source-line-no">007</span><span id="line-7">import net.tvburger.jdl.model.training.Optimizer;</span>
<span class="source-line-no">008</span><span id="line-8">import net.tvburger.jdl.model.training.Regime;</span>
<span class="source-line-no">009</span><span id="line-9"></span>
<span class="source-line-no">010</span><span id="line-10">/**</span>
<span class="source-line-no">011</span><span id="line-11"> * A {@link Regime} decorator that performs &lt;em&gt;online training&lt;/em&gt;</span>
<span class="source-line-no">012</span><span id="line-12"> * (also known as stochastic training).</span>
<span class="source-line-no">013</span><span id="line-13"> *</span>
<span class="source-line-no">014</span><span id="line-14"> * &lt;p&gt;In online mode, the training set is traversed one sample at a time.</span>
<span class="source-line-no">015</span><span id="line-15"> * For each individual sample, the delegate {@link Regime} is invoked with a</span>
<span class="source-line-no">016</span><span id="line-16"> * dataset subset of size one. This provides the highest update frequency,</span>
<span class="source-line-no">017</span><span id="line-17"> * at the cost of noisier gradients compared to batch or mini-batch training.&lt;/p&gt;</span>
<span class="source-line-no">018</span><span id="line-18"> *</span>
<span class="source-line-no">019</span><span id="line-19"> * &lt;h3&gt;Behavior&lt;/h3&gt;</span>
<span class="source-line-no">020</span><span id="line-20"> * &lt;ul&gt;</span>
<span class="source-line-no">021</span><span id="line-21"> *   &lt;li&gt;If constructed with a delegate, training is forwarded to it for each</span>
<span class="source-line-no">022</span><span id="line-22"> *   single-sample subset.&lt;/li&gt;</span>
<span class="source-line-no">023</span><span id="line-23"> *   &lt;li&gt;If constructed without a delegate, the default regime provided by</span>
<span class="source-line-no">024</span><span id="line-24"> *   {@link DelegatedRegime} is used, which directly calls the</span>
<span class="source-line-no">025</span><span id="line-25"> *   {@link Optimizer} once per sample.&lt;/li&gt;</span>
<span class="source-line-no">026</span><span id="line-26"> * &lt;/ul&gt;</span>
<span class="source-line-no">027</span><span id="line-27"> *</span>
<span class="source-line-no">028</span><span id="line-28"> * @see DelegatedRegime</span>
<span class="source-line-no">029</span><span id="line-29"> */</span>
<span class="source-line-no">030</span><span id="line-30">@Strategy(role = Strategy.Role.CONCRETE)</span>
<span class="source-line-no">031</span><span id="line-31">public final class OnlineRegime extends DelegatedRegime {</span>
<span class="source-line-no">032</span><span id="line-32"></span>
<span class="source-line-no">033</span><span id="line-33">    /**</span>
<span class="source-line-no">034</span><span id="line-34">     * Creates a new online regime with no delegate.</span>
<span class="source-line-no">035</span><span id="line-35">     * &lt;p&gt;In this mode the optimizer is invoked once per sample directly.&lt;/p&gt;</span>
<span class="source-line-no">036</span><span id="line-36">     */</span>
<span class="source-line-no">037</span><span id="line-37">    public OnlineRegime() {</span>
<span class="source-line-no">038</span><span id="line-38">        this(null);</span>
<span class="source-line-no">039</span><span id="line-39">    }</span>
<span class="source-line-no">040</span><span id="line-40"></span>
<span class="source-line-no">041</span><span id="line-41">    /**</span>
<span class="source-line-no">042</span><span id="line-42">     * Creates a new online regime that delegates to the given regime.</span>
<span class="source-line-no">043</span><span id="line-43">     *</span>
<span class="source-line-no">044</span><span id="line-44">     * @param regime the underlying regime to delegate to, or {@code null} for standalone online mode</span>
<span class="source-line-no">045</span><span id="line-45">     */</span>
<span class="source-line-no">046</span><span id="line-46">    public OnlineRegime(Regime regime) {</span>
<span class="source-line-no">047</span><span id="line-47">        super(regime);</span>
<span class="source-line-no">048</span><span id="line-48">    }</span>
<span class="source-line-no">049</span><span id="line-49"></span>
<span class="source-line-no">050</span><span id="line-50">    /**</span>
<span class="source-line-no">051</span><span id="line-51">     * Trains the given estimation function in online mode.</span>
<span class="source-line-no">052</span><span id="line-52">     * &lt;p&gt;</span>
<span class="source-line-no">053</span><span id="line-53">     * Each sample of the training set is wrapped in a singleton subset,</span>
<span class="source-line-no">054</span><span id="line-54">     * and the delegate regime is invoked once per sample.</span>
<span class="source-line-no">055</span><span id="line-55">     * &lt;/p&gt;</span>
<span class="source-line-no">056</span><span id="line-56">     *</span>
<span class="source-line-no">057</span><span id="line-57">     * @param estimationFunction the model to train</span>
<span class="source-line-no">058</span><span id="line-58">     * @param trainingSet        the dataset to iterate over sample by sample</span>
<span class="source-line-no">059</span><span id="line-59">     * @param objective          the objective (loss) function</span>
<span class="source-line-no">060</span><span id="line-60">     * @param optimizer          the optimizer to apply updates</span>
<span class="source-line-no">061</span><span id="line-61">     * @param &lt;E&gt;                the type of estimation function</span>
<span class="source-line-no">062</span><span id="line-62">     */</span>
<span class="source-line-no">063</span><span id="line-63">    @Override</span>
<span class="source-line-no">064</span><span id="line-64">    public &lt;E extends EstimationFunction&gt; void train(E estimationFunction, DataSet trainingSet, ObjectiveFunction objective, Optimizer&lt;? super E&gt; optimizer) {</span>
<span class="source-line-no">065</span><span id="line-65">        for (int i = 0; i &lt; trainingSet.samples().size(); i++) {</span>
<span class="source-line-no">066</span><span id="line-66">            regime.train(estimationFunction, trainingSet.subset(i, i + 1), objective, optimizer);</span>
<span class="source-line-no">067</span><span id="line-67">        }</span>
<span class="source-line-no">068</span><span id="line-68">    }</span>
<span class="source-line-no">069</span><span id="line-69"></span>
<span class="source-line-no">070</span><span id="line-70">}</span>




























































</pre>
</div>
</main>
</body>
</html>
