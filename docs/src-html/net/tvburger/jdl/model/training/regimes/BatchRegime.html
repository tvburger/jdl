<!DOCTYPE HTML>
<html lang>
<head>
<!-- Generated by javadoc (24) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: net.tvburger.jdl.model.training.regimes, class: BatchRegime">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../../resource-files/stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">package net.tvburger.jdl.model.training.regimes;</span>
<span class="source-line-no">002</span><span id="line-2"></span>
<span class="source-line-no">003</span><span id="line-3">import net.tvburger.jdl.common.patterns.Strategy;</span>
<span class="source-line-no">004</span><span id="line-4">import net.tvburger.jdl.model.DataSet;</span>
<span class="source-line-no">005</span><span id="line-5">import net.tvburger.jdl.model.training.ObjectiveFunction;</span>
<span class="source-line-no">006</span><span id="line-6">import net.tvburger.jdl.model.training.Optimizer;</span>
<span class="source-line-no">007</span><span id="line-7">import net.tvburger.jdl.model.training.Regime;</span>
<span class="source-line-no">008</span><span id="line-8">import net.tvburger.jdl.model.training.TrainableFunction;</span>
<span class="source-line-no">009</span><span id="line-9"></span>
<span class="source-line-no">010</span><span id="line-10">/**</span>
<span class="source-line-no">011</span><span id="line-11"> * A training regime that performs classic &lt;strong&gt;batch training&lt;/strong&gt;.</span>
<span class="source-line-no">012</span><span id="line-12"> * &lt;p&gt;</span>
<span class="source-line-no">013</span><span id="line-13"> * In batch training, the optimizer is applied once to the entire training set</span>
<span class="source-line-no">014</span><span id="line-14"> * in a single call. This is equivalent to full-batch gradient descent, where</span>
<span class="source-line-no">015</span><span id="line-15"> * all samples are used together to compute parameterGradients and update parameters.</span>
<span class="source-line-no">016</span><span id="line-16"> * &lt;/p&gt;</span>
<span class="source-line-no">017</span><span id="line-17"> *</span>
<span class="source-line-no">018</span><span id="line-18"> * &lt;h2&gt;Behavior&lt;/h2&gt;</span>
<span class="source-line-no">019</span><span id="line-19"> * &lt;ul&gt;</span>
<span class="source-line-no">020</span><span id="line-20"> *   &lt;li&gt;Delegates directly to {@link Optimizer#optimize} with the provided</span>
<span class="source-line-no">021</span><span id="line-21"> *       estimation function, dataset, and objective.&lt;/li&gt;</span>
<span class="source-line-no">022</span><span id="line-22"> *   &lt;li&gt;No batching or shuffling is performed; the optimizer receives the</span>
<span class="source-line-no">023</span><span id="line-23"> *       complete dataset.&lt;/li&gt;</span>
<span class="source-line-no">024</span><span id="line-24"> * &lt;/ul&gt;</span>
<span class="source-line-no">025</span><span id="line-25"> *</span>
<span class="source-line-no">026</span><span id="line-26"> * &lt;h2&gt;Usage&lt;/h2&gt;</span>
<span class="source-line-no">027</span><span id="line-27"> * This regime is useful for small datasets where processing the entire batch</span>
<span class="source-line-no">028</span><span id="line-28"> * in memory is feasible. For larger datasets or stochastic training, see</span>
<span class="source-line-no">029</span><span id="line-29"> * mini-batch or online regimes.</span>
<span class="source-line-no">030</span><span id="line-30"> *</span>
<span class="source-line-no">031</span><span id="line-31"> * @see Regime</span>
<span class="source-line-no">032</span><span id="line-32"> * @see Optimizer</span>
<span class="source-line-no">033</span><span id="line-33"> */</span>
<span class="source-line-no">034</span><span id="line-34">@Strategy(Strategy.Role.CONCRETE)</span>
<span class="source-line-no">035</span><span id="line-35">public final class BatchRegime implements Regime {</span>
<span class="source-line-no">036</span><span id="line-36"></span>
<span class="source-line-no">037</span><span id="line-37">    /**</span>
<span class="source-line-no">038</span><span id="line-38">     * Trains the given estimation function using the full training set in one step.</span>
<span class="source-line-no">039</span><span id="line-39">     *</span>
<span class="source-line-no">040</span><span id="line-40">     * @param estimationFunction the model or function being trained</span>
<span class="source-line-no">041</span><span id="line-41">     * @param trainingSet        the dataset containing all training samples</span>
<span class="source-line-no">042</span><span id="line-42">     * @param objective          the objective/loss function</span>
<span class="source-line-no">043</span><span id="line-43">     * @param optimizer          the optimizer that updates the function parameters</span>
<span class="source-line-no">044</span><span id="line-44">     * @param &lt;E&gt;                the type of estimation function being trained</span>
<span class="source-line-no">045</span><span id="line-45">     */</span>
<span class="source-line-no">046</span><span id="line-46">    @Override</span>
<span class="source-line-no">047</span><span id="line-47">    public &lt;E extends TrainableFunction&lt;N&gt;, N extends Number&gt; void train(E estimationFunction, DataSet&lt;N&gt; trainingSet, ObjectiveFunction&lt;N&gt; objective, Optimizer&lt;? super E, N&gt; optimizer, int step) {</span>
<span class="source-line-no">048</span><span id="line-48">        optimizer.optimize(estimationFunction, trainingSet, objective, step);</span>
<span class="source-line-no">049</span><span id="line-49">    }</span>
<span class="source-line-no">050</span><span id="line-50">}</span>




























































</pre>
</div>
</main>
</body>
</html>
